{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkT1vvhBAdMq"
   },
   "source": [
    "# Map Reduce Recommendation Engine\n",
    "\n",
    "In this lesson, we'll build a cosine similarity recommendation engine that uses the movie lens data set.\n",
    "\n",
    "### Lesson goals:\n",
    "* Build the MapReduce cosine similarity recommendation engine from smaller components\n",
    "* Show the transition of data into each component\n",
    "* Produce recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu4urxZw-Ndl"
   },
   "source": [
    "### For demonstration purposes, open the data sources and save them locally. \n",
    "\n",
    "The original source can be found here;\n",
    "\n",
    "* https://grouplens.org/datasets/movielens/100k/\n",
    "* Data: https://files.grouplens.org/datasets/movielens/ml-100k/u.data\n",
    "* Labels: https://files.grouplens.org/datasets/movielens/ml-100k/u.item\n",
    "\n",
    "This next cell will show the data structure we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Ratings Data\n",
      "UserID movieID rating timestamp \n",
      "\n",
      "196\t242\t3\t881250949\n",
      "\n",
      "186\t302\t3\t891717742\n",
      "\n",
      "22\t377\t1\t878887116\n",
      "\n",
      "244\t51\t2\t880606923\n",
      "\n",
      "166\t346\t1\t886397596\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MovideID movieName date hyperlink\n",
      "\n",
      "1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
      "\n",
      "2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
      "\n",
      "3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
      "\n",
      "4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
      "\n",
      "5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "data_source = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.data'\n",
    "labels_source = 'https://files.grouplens.org/datasets/movielens/ml-100k/u.item'\n",
    "def download_source_file(url,file_name,limit=None):\n",
    "    f = requests.get(url).text\n",
    "    lines = f.split('\\t')\n",
    "    with open(file_name, 'w',encoding='utf-8') as outfile:\n",
    "        lines = '\\t'.join(lines)\n",
    "        if limit:\n",
    "            lines = lines[:int(len(lines)*limit)] #limit to only a fraction of the data\n",
    "        outfile.writelines(lines)\n",
    "\n",
    "def open_data(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines\n",
    "        \n",
    "download_source_file(data_source,'data1.txt')\n",
    "download_source_file(labels_source,'labels1.txt')\n",
    "\n",
    "\n",
    "data_txt = open_data('data1.txt')\n",
    "print('Movie Ratings Data')\n",
    "print('UserID movieID rating timestamp \\n')\n",
    "for row in data_txt[:5]:\n",
    "    print(row)\n",
    "\n",
    "print('\\n'*5)\n",
    "\n",
    "labels_txt = open_data('labels1.txt')\n",
    "print('MovideID movieName date hyperlink\\n')\n",
    "for label in labels_txt[:5]:\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMWXcmwhRO_a"
   },
   "source": [
    "# Step 1: Parse the dataset into map reduce\n",
    "We create key value pairs for ever user and the set of movies they rated (and the ratings they gave them)\n",
    "\n",
    "The goals of step 1\n",
    "* read/parse our text document data\n",
    "* map the data into key value pairs of keys: userID, values:(movieID, rating)\n",
    "* reduce this mapping into keys: userID, values: `[(movieID1,rating1),(movieID2,rating2),....]`\n",
    "\n",
    "The following cell will make a `rec_step1.py` file and we can then run it as if we were running it in terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 618,
     "status": "ok",
     "timestamp": 1675024931319,
     "user": {
      "displayName": "Joe Ganser",
      "userId": "13722397183940051337"
     },
     "user_tz": 300
    },
    "id": "sDrM48-m_wrd",
    "outputId": "1b818ee3-0437-4068-d97f-5177e7fba93d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rec_step1.py\n"
     ]
    }
   ],
   "source": [
    "%%file rec_step1.py \n",
    "from mrjob.job import MRJob\n",
    "class rec_step1(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        try:\n",
    "            (userID, movieID, rating, timestamp) = line.split('\\t')\n",
    "        except:\n",
    "            (userID, movieID, rating, timestamp) = None,None,0,None\n",
    "        yield  userID, (movieID, float(rating)) \n",
    "\n",
    "    def reducer(self, user_id, itemRatings):\n",
    "        ratings = []\n",
    "        for movieID, rating in itemRatings:\n",
    "            ratings.append((movieID, rating))\n",
    "        #reducer: for every user_id key, we have a list of ratings in the form [(movieID1,rating1),(movieID2,rating2),...]\n",
    "        yield user_id, ratings\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    rec_step1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run `rec_step1.py` as if we were in terminal, on the `data1.txt` file we saved from our data locally. Save the output to `step1output.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /var/folders/hj/xyjyq1ds11n1ycjbp53_4svw0000gp/T/rec_step1.teaching.20230201.010956.958721\n",
      "Running step 1 of 1...\n",
      "job output is in /var/folders/hj/xyjyq1ds11n1ycjbp53_4svw0000gp/T/rec_step1.teaching.20230201.010956.958721/output\n",
      "Streaming final output from /var/folders/hj/xyjyq1ds11n1ycjbp53_4svw0000gp/T/rec_step1.teaching.20230201.010956.958721/output...\n",
      "Removing temp directory /var/folders/hj/xyjyq1ds11n1ycjbp53_4svw0000gp/T/rec_step1.teaching.20230201.010956.958721...\n",
      "CPU times: user 21.5 ms, sys: 22.9 ms, total: 44.4 ms\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python rec_step1.py data1.txt > step1output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at the first few lines saved in our `step1output.txt` file, with a little text to describe it's meaning;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id:  844    Ratings:  [['22', 4.0], ['403', 3.0], ['195', 3.0], ['90', 3.0], ['423', 3.0]] ....\n",
      "\n",
      "\n",
      "user_id:  845    Ratings:  [['311', 4.0], ['903', 4.0], ['877', 2.0], ['750', 3.0], ['1592', 3.0]] ....\n",
      "\n",
      "\n",
      "user_id:  846    Ratings:  [['1074', 3.0], ['94', 4.0], ['627', 4.0], ['57', 2.0], ['377', 2.0]] ....\n",
      "\n",
      "\n",
      "user_id:  847    Ratings:  [['290', 4.0], ['185', 2.0], ['826', 3.0], ['288', 4.0], ['405', 3.0]] ....\n",
      "\n",
      "\n",
      "user_id:  848    Ratings:  [['164', 5.0], ['294', 5.0], ['1126', 5.0], ['481', 3.0], ['69', 2.0]] ....\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in open('step1output.txt','r').readlines()[:5]:\n",
    "    user_id,ratings= line.split('\\t')\n",
    "    user_id = int(user_id.replace('\"',''))\n",
    "    ratings = eval(ratings)[:5]\n",
    "    print('user_id: ',user_id,'   Ratings: ',ratings,'....')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_Mcehn2RwAC"
   },
   "source": [
    "# Step 2: \n",
    "\n",
    "Step 2 has several components, and it takes step1 as an input using `step1output.txt`\n",
    "\n",
    "* Map the line by line input of `(userID, [(movieID1,rating1),(movieID2,rating2),....])` to key-value pairs of\n",
    "`keys: (movieID1,movieID2), values: (rating1,rating2)`. Do this by getting every combination of movies watched by every unique user.\n",
    "\n",
    "* For each key-value pair, reduce these values by getting the \n",
    "    * count of users that watched both movies\n",
    "    * cosine similarity for the ratings of both movies;\n",
    "        * Each movie will have ratings in the form of \n",
    "            * `movie1: (user1rating, user2rating, user3rating,...)`\n",
    "            * `movie2: (user1rating, user2rating, user3rating,...)`\n",
    "            * treat these as vectors for a dot product for multiplication.\n",
    "    * The output should be:\n",
    "        * `keys: (movie1,movie2), values: (cosineSimilarity, numberOfTimesUsersWatchedBoth)`\n",
    "        * Filter only those with cosineSimilarity>0.95, numberOfTimesUsersWatchedBoth >10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1675028924124,
     "user": {
      "displayName": "Joe Ganser",
      "userId": "13722397183940051337"
     },
     "user_tz": 300
    },
    "id": "N-XtCSsmStD7",
    "outputId": "2ef59890-b7a6-4d0f-c405-89e9183e6b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rec_step2.py\n"
     ]
    }
   ],
   "source": [
    "%%file rec_step2.py \n",
    "#make this cell a python file\n",
    "from itertools import combinations\n",
    "from math import sqrt\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class rec_step2(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        user_id,itemRatings = line.split('\\t')\n",
    "        for itemRating1, itemRating2 in combinations(eval(itemRatings), 2):\n",
    "            movieID1,rating1 = itemRating1[0],itemRating1[1]\n",
    "            movieID2,rating2 = itemRating2[0],itemRating2[1]\n",
    "            yield (movieID1, movieID2), (rating1, rating2)\n",
    "            yield (movieID2, movieID1), (rating2, rating1)\n",
    "    def cosine_similarity(self, ratingPairs):\n",
    "        numPairs = 0\n",
    "        sum_xx = sum_yy = sum_xy = 0\n",
    "        for ratingX, ratingY in ratingPairs:\n",
    "            sum_xx += ratingX * ratingX\n",
    "            sum_yy += ratingY * ratingY\n",
    "            sum_xy += ratingX * ratingY\n",
    "            numPairs += 1\n",
    "\n",
    "        numerator = sum_xy\n",
    "        denominator = sqrt(sum_xx) * sqrt(sum_yy)\n",
    "\n",
    "        score = 0\n",
    "        if (denominator):\n",
    "            score = (numerator / (float(denominator)))\n",
    "        return (score, numPairs)\n",
    "    \n",
    "    def reducer(self, moviePair, ratingPairs,minPairs=10,minScore=0.95):\n",
    "        score, numPairs = self.cosine_similarity(ratingPairs)\n",
    "        if (numPairs > minPairs and score > minScore):\n",
    "            yield moviePair, (score, numPairs)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    rec_step2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run `rec_step2.py` on `step1output.txt` and save the file to `step2output.txt` \n",
    "* Print the first 10 lines saved to `step2output.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "output_embedded_package_id": "1xQcUjpISWbr35ddozFYJaxpeYbepNxW_"
    },
    "executionInfo": {
     "elapsed": 69394,
     "status": "ok",
     "timestamp": 1675028998887,
     "user": {
      "displayName": "Joe Ganser",
      "userId": "13722397183940051337"
     },
     "user_tz": 300
    },
    "id": "Eh79iZkfXWvC",
    "outputId": "496bfe1e-72d5-4b7e-8bb5-029d27706562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /var/folders/hj/xyjyq1ds11n1ycjbp53_4svw0000gp/T/rec_step2.teaching.20230201.012146.874491\n",
      "Running step 1 of 1...\n",
      "job output is in /var/folders/hj/xyjyq1ds11n1ycjbp53_4svw0000gp/T/rec_step2.teaching.20230201.012146.874491/output\n",
      "Streaming final output from /var/folders/hj/xyjyq1ds11n1ycjbp53_4svw0000gp/T/rec_step2.teaching.20230201.012146.874491/output...\n",
      "Removing temp directory /var/folders/hj/xyjyq1ds11n1ycjbp53_4svw0000gp/T/rec_step2.teaching.20230201.012146.874491...\n",
      "[\"740\",\"132\"]\t[0.96477212667565,17]\n",
      "\n",
      "[\"740\",\"133\"]\t[0.9549950604770451,19]\n",
      "\n",
      "[\"740\",\"134\"]\t[0.9704274486322576,17]\n",
      "\n",
      "[\"740\",\"143\"]\t[0.9650419442914718,19]\n",
      "\n",
      "[\"740\",\"154\"]\t[0.9598987017177196,15]\n",
      "\n",
      "[\"740\",\"155\"]\t[0.9548872180451126,13]\n",
      "\n",
      "[\"740\",\"162\"]\t[0.9610400702474754,11]\n",
      "\n",
      "[\"740\",\"164\"]\t[0.952830641518021,17]\n",
      "\n",
      "[\"740\",\"178\"]\t[0.9536746412526173,11]\n",
      "\n",
      "[\"740\",\"185\"]\t[0.9538407392261975,19]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python rec_step2.py step1output.txt > step2output.txt\n",
    "for line in open('step2output.txt','r').readlines()[:10]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: sort the similarities, load the movie names and output similarities\n",
    "\n",
    "* Initialize the mapper using `mapper_init` to open the `labels1.txt` file to give the actual movie names instead of numbers\n",
    "\n",
    "* Map the output of step 2 to `keys: (movieName1,cosineScore), values: (movieName2, number_users_who_watched_both)`\n",
    "\n",
    "* Reduce the output of the mapper such that for every `movie1` we get a `(movie2, cosineScore, number_users_who_watched_both)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file rec_step3.py\n",
    "from mrjob.job import MRJob\n",
    "import os\n",
    "class rec_step3(MRJob):\n",
    "    def mapper_init(self,labelfilename='labels1.txt'):\n",
    "        # Load database of movie names.\n",
    "        self.movieNames = {}\n",
    "        #change the file path to wherever your current main directory is\n",
    "        filepath = '/Users/teaching/Documents/github/teaching/SaintPeters/DS610/week9'\n",
    "        filepath = os.path.join(filepath,labelfilename)\n",
    "        with open(filepath,'r') as f:\n",
    "            for line in f:\n",
    "                fields = line.split('|')\n",
    "                self.movieNames[int(fields[0])] = fields[1]\n",
    "                \n",
    "    def mapper(self, _, line):\n",
    "        moviePair,scores = line.split('\\t')\n",
    "        score, n = eval(scores)\n",
    "        movie1, movie2 = eval(moviePair)\n",
    "        yield (self.movieNames[int(movie1)], score),(self.movieNames[int(movie2)], n)\n",
    "        \n",
    "    def reducer(self, movieScore, similarN):\n",
    "        movie1, score = movieScore\n",
    "        for movie2, n in similarN:\n",
    "            yield movie1, (movie2, score, n)\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    rec_step3.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `rec_step3.py` script on the `step2output.txt` file from above, and save it to `step3output.txt` as if in terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python rec_step3.py step2output.txt > step3output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first 10 lines of `step3output.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('step3output.txt','r').readlines()[:10]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uEgnnIu_ODs"
   },
   "outputs": [],
   "source": [
    "!pipreqs --force /Users/teaching/Documents/github/teaching/SaintPeters/DS610/week9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOdF2gBTmZ+DMfa9rJ5RAGM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
