{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 9 BDS4440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "m = 10000\n",
    "idx = np.random.permutation(60000)[:m]\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "mnist.target = mnist.target.astype(np.uint8)\n",
    "X = mnist['data'][idx]\n",
    "y = mnist['target'][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Using the TSNE algorithm, comppress the MNIST feature data into 2 components. Plot these components using a scatter plot.\n",
    "Use the `.fit_transform()` method (of the `TSNE` package) to transform the MNIST features into a data set comprising of two features. In the scatter plot, include a `colorbar()`, and in the `plt.scatter()` function specify the colors as the target, i.e. `c=y` and the color mapping as `cmap='jet'`. If you dont know any of these terms/functions, google them and read the technical document!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "plt.figure(figsize=(13,10))\n",
    "#tsne = TSNE complete code\n",
    "X_reduced = #complete code\n",
    "plt.scatter(#complete code, #complete code, c=y, cmap=\"jet\")\n",
    "plt.axis('off')\n",
    "#complete code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: \n",
    "\n",
    "Using the reduced data set made from the TSNE package of 2 components (from problem 1), run the K means algorithm through a range of values for K.\n",
    "\n",
    "At each K, get the sum of squared errors (the inertia) and the silhouette score. Save these scores to lists so you can plot them side by side and see how the SSE and silhoette vary with K.\n",
    "\n",
    "* `sse = model.inertia_`\n",
    "\n",
    "Recall that inorder to run the silhouette score, you must also predict the cluster labels of each row.\n",
    "* `labels = model.labels_`\n",
    "\n",
    "To make the silhoette score, you must include these labels as well as the features\n",
    "\n",
    "* `silhoette_score(df[features],df['cluster_labels'],metric='euclidean')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pandas as pd\n",
    "\n",
    "scores = #complete code\n",
    "for k in range(2,40):\n",
    "    model = #complete code\n",
    "    model.fit(X_reduced)\n",
    "    df = pd.DataFrame(X_reduced)\n",
    "    df['cluster'] = #complete code\n",
    "    silhouette = #complete code\n",
    "    sse = #complete code\n",
    "    scores['sse'].append(sse)\n",
    "    scores['silhouette'].append(silhouette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: \n",
    "\n",
    "Make two plots. One of the K vs SSE and the other of K vs silhouette score. Make these plots side by side and parallel using the `plt.subplot` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot#complete code\n",
    "plt.scatter(#complete code,#complete code)\n",
    "plt.title('K vs SSE')\n",
    "\n",
    "plt.subplot#complete code\n",
    "plt.scatter(#complete code,#complete code)\n",
    "plt.title('K vs  silhoette')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "## Look at your plot in question 1 and your plots in question 3. How do they compare? Is it obvious that K means fits well to the t-sne reduced data? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `put your answer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the iris data for questions 5 and on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "X,y = load_iris(return_X_y=True)\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: Use the `StandardScaler` preprocessor to take all the iris features and put them into a standard scaler format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import #complete code\n",
    "ss = #complete code\n",
    "X = ss.#complete code\n",
    "df[[0,1,2,3]] = #complete code\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: \n",
    "\n",
    "Test different approachs to hierarchial clustering  (different linkage methods). Loop through the list of `['single','complete','average','ward']` to create a different clustering (using the `linkage()` function) the scaled features produced in question 5. Then using the `pdist` function on the scaled features, as well as the hierarchial cluster itsself,  find the cophenetic correlation coefficient using the `cophenet` function. Print the coefficient for each linkage proctool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage,cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "for L in #complete code:\n",
    "    Z = #complete code\n",
    "    c,dist = cophenet#complete code\n",
    "    print(c,' L: {}'.format(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7: \n",
    "\n",
    "Using the best performing linkage protocol (highest cophenetic coefficient), make a plot of the dendrogram using the `dendrogram(Z)` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "Z = #complete code\n",
    "dn = #complete code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8: \n",
    "\n",
    "Using the `fcluster` function on the clustering protocol used in question 7, find the max distance at which there is only 1 unique cluster.\n",
    "This means that the set of clusters returned by the `fcluster` function will only have one unique value.\n",
    "Loop through a range of distances to find that value. Print that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram,linkage,cophenet,fcluster\n",
    "\n",
    "Z = linkage#complete code\n",
    "\n",
    "for max_dist in list(np.arange(0,4,0.1)):\n",
    "    clusters = fcluster(#complete code)\n",
    "    if len(set(clusters))==#complete code:\n",
    "        print('Sinlge Clusters merged at {}'.format(max_dist))\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
