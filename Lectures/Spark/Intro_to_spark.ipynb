{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Spark with Python\n",
    "\n",
    "by Joe Ganser\n",
    "\n",
    "\n",
    "## Beginning a Py-Spark session\n",
    "\n",
    "The begin working with spark on a local machine (with Python), we should import the `SparkSession` package and use it's `.getOrCreate()` method to develop a spark work flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaIN5XhF_FiP",
    "outputId": "729aca13-afd9-494b-ac3c-00bc4ebe6bdd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/08 15:50:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "except:\n",
    "    !pip install pyspark\n",
    "    from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example\")\\\n",
    "                            .config(\"spark.some.config.option\", \"some-value\")\\\n",
    "                            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vneZdco7R8ka"
   },
   "source": [
    "## Load a data frame\n",
    "\n",
    "Heres a a simple example of loading a dataframe from a source on <a href=\"https://github.com/JoeGanser/Spark-The-Definitive-Guide/blob/master/data/flight-data/csv/2015-summary.csv\">Github</a>.\n",
    "\n",
    "* Add the remote file to our spark context using `spark.sparkContext.addFile(url)`\n",
    "* Use the `SparkFiles` method to access temporarily downloaded csv file to our `SparkSession`\n",
    "* Tell spark we want to look for the dataframes header by specifying `header=True`\n",
    "* Tell spark to infer the schema (figure out the column name data types), etc using `inferSchema=True`.\n",
    "* Show the first 20 rows uing the `.show()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCP-hEBsQj62",
    "outputId": "fa7d753c-cf0e-4f49-bd8d-fc17193c1cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/JoeGanser/Spark-The-Definitive-Guide/master/data/flight-data/csv/'\n",
    "csv_file = \"2015-summary.csv\"\n",
    "url = url+csv_file\n",
    "from pyspark import SparkFiles\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "flightData2015 = spark.read.csv(\"file://\"+SparkFiles.get(csv_file), header=True, inferSchema= True)\n",
    "flightData2015.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## printSchema( ) method\n",
    "\n",
    "Schemas are an important part of working with Spark. They tell use the column names, data types and if the column can contain null values. We can save computational power by telling Spark the schema of data source before loading it. If we want to take a look at a dataframe's schema we use the `.printSchema()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7qjNfy5Qypm",
    "outputId": "e5eb02d2-8c41-4dab-f377-10f2a6168357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a specific columns\n",
    "\n",
    "To select a specific column you use the `.select(columnname1, columnname2..)` method on the dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hq3fhEW1bxqs",
    "outputId": "181badf4-d438-4f4e-a99c-3491b607954b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|count|\n",
      "+--------------------+-----+\n",
      "|       United States|   15|\n",
      "|       United States|    1|\n",
      "|       United States|  344|\n",
      "|               Egypt|   15|\n",
      "|       United States|   62|\n",
      "|       United States|    1|\n",
      "|       United States|   62|\n",
      "|          Costa Rica|  588|\n",
      "|             Senegal|   40|\n",
      "|             Moldova|    1|\n",
      "|       United States|  325|\n",
      "|       United States|   39|\n",
      "|              Guyana|   64|\n",
      "|               Malta|    1|\n",
      "|            Anguilla|   41|\n",
      "|             Bolivia|   30|\n",
      "|       United States|    6|\n",
      "|             Algeria|    4|\n",
      "|Turks and Caicos ...|  230|\n",
      "|       United States|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selection = flightData2015.select('DEST_COUNTRY_NAME','count')\n",
    "selection.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting with SQL like expressions\n",
    "\n",
    "We can select specific columns and even pass aggregation functions (e.g. `count`,`max`,`sum`) using the `selectExpr()` method on Spark dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|DEST_COUNTRY_NAME|count|\n",
      "+-----------------+-----+\n",
      "|    United States|   15|\n",
      "|    United States|    1|\n",
      "|    United States|  344|\n",
      "|            Egypt|   15|\n",
      "|    United States|   62|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.selectExpr('DEST_COUNTRY_NAME', 'count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+----------+\n",
      "|count(DEST_COUNTRY_NAME)|max(count)|\n",
      "+------------------------+----------+\n",
      "|                     256|    370002|\n",
      "+------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.selectExpr('count(DEST_COUNTRY_NAME)', 'max(count)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame analytics\n",
    "\n",
    "We can describe the dataframe using the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9usMYo6nb7ay",
    "outputId": "b58474d2-fb47-431e-a2fd-5f75d19f5100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+\n",
      "|summary|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|             count|\n",
      "+-------+-----------------+-------------------+------------------+\n",
      "|  count|              256|                256|               256|\n",
      "|   mean|             null|               null|       1770.765625|\n",
      "| stddev|             null|               null|23126.516918551915|\n",
      "|    min|          Algeria|             Angola|                 1|\n",
      "|    max|           Zambia|            Vietnam|            370002|\n",
      "+-------+-----------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine this method with the `select()` in a code chain to act only on specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+\n",
      "|summary|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n",
      "+-------+-----------------+-------------------+\n",
      "|  count|              256|                256|\n",
      "|   mean|             null|               null|\n",
      "| stddev|             null|               null|\n",
      "|    min|          Algeria|             Angola|\n",
      "|    max|           Zambia|            Vietnam|\n",
      "+-------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.select('DEST_COUNTRY_NAME','ORIGIN_COUNTRY_NAME')\\\n",
    "              .describe()\\\n",
    "              .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by aggregation\n",
    "\n",
    "We can group by specific columns using the `.groupby()` and `.agg()` functions.\n",
    "\n",
    "For every origin country in the data set, count the number of destination countries. Sort the values in decreasing order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------+\n",
      "| ORIGIN_COUNTRY_NAME|count(DEST_COUNTRY_NAME)|\n",
      "+--------------------+------------------------+\n",
      "|       United States|                     132|\n",
      "|            Paraguay|                       1|\n",
      "|            Anguilla|                       1|\n",
      "|              Russia|                       1|\n",
      "|              Guyana|                       1|\n",
      "|             Senegal|                       1|\n",
      "|              Sweden|                       1|\n",
      "|            Kiribati|                       1|\n",
      "|               Palau|                       1|\n",
      "|         Philippines|                       1|\n",
      "|           Singapore|                       1|\n",
      "|            Malaysia|                       1|\n",
      "|                Fiji|                       1|\n",
      "|              Turkey|                       1|\n",
      "|             Germany|                       1|\n",
      "|              Jordan|                       1|\n",
      "|Turks and Caicos ...|                       1|\n",
      "|              France|                       1|\n",
      "|              Greece|                       1|\n",
      "|British Virgin Is...|                       1|\n",
      "+--------------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count,col\n",
    "flightData2015.groupby('ORIGIN_COUNTRY_NAME')\\\n",
    "              .agg(count(col('DEST_COUNTRY_NAME')))\\\n",
    "              .orderBy(\"count(DEST_COUNTRY_NAME)\",ascending=False)\\\n",
    "              .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a new column to the dataset\n",
    "\n",
    "If we want to add a new column to our dataframe, we can use the `.withColumn(column_name, column_data)` method, where `column_name` and `column_data` are the arguments.\n",
    "\n",
    "In this example we create a columnd `double the count` that takes the values of the `count` column and doubles them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSnBjm8_b_rB",
    "outputId": "91461fa8-2159-48d4-f205-677fec8a7430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+----------------+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|double the count|\n",
      "+--------------------+-------------------+-----+----------------+\n",
      "|       United States|            Romania|   15|              30|\n",
      "|       United States|            Croatia|    1|               2|\n",
      "|       United States|            Ireland|  344|             688|\n",
      "|               Egypt|      United States|   15|              30|\n",
      "|       United States|              India|   62|             124|\n",
      "|       United States|          Singapore|    1|               2|\n",
      "|       United States|            Grenada|   62|             124|\n",
      "|          Costa Rica|      United States|  588|            1176|\n",
      "|             Senegal|      United States|   40|              80|\n",
      "|             Moldova|      United States|    1|               2|\n",
      "|       United States|       Sint Maarten|  325|             650|\n",
      "|       United States|   Marshall Islands|   39|              78|\n",
      "|              Guyana|      United States|   64|             128|\n",
      "|               Malta|      United States|    1|               2|\n",
      "|            Anguilla|      United States|   41|              82|\n",
      "|             Bolivia|      United States|   30|              60|\n",
      "|       United States|           Paraguay|    6|              12|\n",
      "|             Algeria|      United States|    4|               8|\n",
      "|Turks and Caicos ...|      United States|  230|             460|\n",
      "|       United States|          Gibraltar|    1|               2|\n",
      "+--------------------+-------------------+-----+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015 = flightData2015.withColumn('double the count',flightData2015['count']*2)\n",
    "flightData2015.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping columns\n",
    "\n",
    "We can drop columns using the `.drop()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ea37R_9AcTfF",
    "outputId": "42e41da6-174b-4f4c-c4cb-0f1f9bc3bbb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015 = flightData2015.drop('double the count')\n",
    "flightData2015.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming Columns\n",
    "\n",
    "We can rename columns using the `.withColumnRenamed(old_column_name, new_column_name)` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0vidQ2tcbsK",
    "outputId": "ff54055b-95f6-4bff-f670-38bd3ffcf434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----+\n",
      "|                DEST|          ORIGIN|count|\n",
      "+--------------------+----------------+-----+\n",
      "|       United States|         Romania|   15|\n",
      "|       United States|         Croatia|    1|\n",
      "|       United States|         Ireland|  344|\n",
      "|               Egypt|   United States|   15|\n",
      "|       United States|           India|   62|\n",
      "|       United States|       Singapore|    1|\n",
      "|       United States|         Grenada|   62|\n",
      "|          Costa Rica|   United States|  588|\n",
      "|             Senegal|   United States|   40|\n",
      "|             Moldova|   United States|    1|\n",
      "|       United States|    Sint Maarten|  325|\n",
      "|       United States|Marshall Islands|   39|\n",
      "|              Guyana|   United States|   64|\n",
      "|               Malta|   United States|    1|\n",
      "|            Anguilla|   United States|   41|\n",
      "|             Bolivia|   United States|   30|\n",
      "|       United States|        Paraguay|    6|\n",
      "|             Algeria|   United States|    4|\n",
      "|Turks and Caicos ...|   United States|  230|\n",
      "|       United States|       Gibraltar|    1|\n",
      "+--------------------+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.withColumnRenamed('DEST_COUNTRY_NAME','DEST')\\\n",
    "              .withColumnRenamed('ORIGIN_COUNTRY_NAME','ORIGIN')\\\n",
    "              .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Columns for specific row values\n",
    "\n",
    "We can filter the dataframe to display only rows yielding specific values using the `.filter()` method. The arguments use a SQL like syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLCQitDictNC",
    "outputId": "0732f4ce-bf6a-4702-efd5-e45a197bf5cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-----+\n",
      "|DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+--------------------+-----+\n",
      "|    United States|             Romania|   15|\n",
      "|    United States|             Croatia|    1|\n",
      "|    United States|             Ireland|  344|\n",
      "|    United States|               India|   62|\n",
      "|    United States|           Singapore|    1|\n",
      "|    United States|             Grenada|   62|\n",
      "|    United States|        Sint Maarten|  325|\n",
      "|    United States|    Marshall Islands|   39|\n",
      "|    United States|            Paraguay|    6|\n",
      "|    United States|           Gibraltar|    1|\n",
      "|    United States|Federated States ...|   69|\n",
      "|    United States|              Russia|  161|\n",
      "|    United States|         Netherlands|  660|\n",
      "|    United States|             Senegal|   42|\n",
      "|    United States|              Angola|   13|\n",
      "|    United States|            Anguilla|   38|\n",
      "|    United States|             Ecuador|  300|\n",
      "|    United States|              Cyprus|    1|\n",
      "|    United States|            Portugal|  134|\n",
      "|    United States|          Costa Rica|  608|\n",
      "+-----------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.filter(\"DEST_COUNTRY_NAME = 'United States'\")\\\n",
    "              .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SQL to query dataframe values\n",
    "\n",
    "We can run sql queries on a dataframe using `spark.sql( query text )` method. But before we can do that, we must first register the table as one that can be queried using sql. This is done using the `.registerTempTable(tablename)` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C7dPJyO3dNNP",
    "outputId": "bc5c8fdc-cc8d-404e-c27c-9cb11703fd77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   DEST_COUNTRY_NAME|\n",
      "+--------------------+\n",
      "|             Algeria|\n",
      "|              Angola|\n",
      "|            Anguilla|\n",
      "| Antigua and Barbuda|\n",
      "|           Argentina|\n",
      "|               Aruba|\n",
      "|           Australia|\n",
      "|             Austria|\n",
      "|          Azerbaijan|\n",
      "|             Bahrain|\n",
      "|            Barbados|\n",
      "|             Belgium|\n",
      "|              Belize|\n",
      "|             Bermuda|\n",
      "|             Bolivia|\n",
      "|Bonaire, Sint Eus...|\n",
      "|              Brazil|\n",
      "|British Virgin Is...|\n",
      "|            Bulgaria|\n",
      "|        Burkina Faso|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Writing in SQL example\n",
    "flightData2015.registerTempTable(\"flightData2015\")\n",
    "\n",
    "spark.sql(\"select distinct DEST_COUNTRY_NAME from flightData2015 order by DEST_COUNTRY_NAME ASC\")\\\n",
    "     .show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OApw5xt6FvnB"
   },
   "source": [
    "## Sources\n",
    "\n",
    "Some of the notes here were taken from the following text book, in conjunction to examples written by myself.\n",
    "\n",
    "* Spark: The Definitive Guide Big Data Processing Made Simple, Bill Chabers & Matel Zaharia, O'Reilly Publications 2018\n",
    "    * Purchase here: <a href='https://www.amazon.com/s?k=spark+the+definitive+guide&crid=2VERI00ZCPTLK&sprefix=spark+the+definitive+guide%2Caps%2C107&ref=nb_sb_noss_1'>Amazon Link</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
