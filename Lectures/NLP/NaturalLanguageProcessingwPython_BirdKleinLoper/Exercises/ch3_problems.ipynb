{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b02077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Man Who Was Thursday by G. K. Chesterton 1908]\n",
      "\n",
      "To Edmund Clerihew Bentley\n",
      "\n",
      "A cloud was on the mind of men, and wailing went the weather,\n",
      "Yea, a sick cloud upon the soul when we were boys together.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
    "sents = sent_tokenizer.tokenize(text)\n",
    "print(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d49f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Man', 'Who', 'Was', 'Thursday', 'by', 'G', 'K', 'Chesterton', 'To', 'Edmund', 'Clerihew', 'Bentley', 'A', 'cloud', 'was', 'on', 'the', 'mind', 'of', 'men', 'and', 'wailing', 'went', 'the', 'weather', 'Yea', 'a', 'sick', 'cloud', 'upon', 'the', 'soul', 'when', 'we', 'were', 'boys', 'together']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# finds any sequence of all possible alphabetical letters,\n",
    "# with one or more characters between a-z or A-Z\n",
    "print(re.findall(r\"[a-zA-Z]+\",sents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e65dcec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Man', 'Who', 'Was', 'Thursday', 'G', 'K', 'Chesterton', 'To', 'Edmund', 'Clerihew', 'Bentley', 'A', 'Yea']\n"
     ]
    }
   ],
   "source": [
    "#finds any sequences with at least one capital leter and zero or more lower case\n",
    "print(re.findall(r\"[A-Z][a-z]*\",sents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cf1e236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Man Who Was Thursday by G. K. Chesterton 1908]\n",
      "\n",
      "To Edmund Clerihew Bentley\n",
      "\n",
      "A cloud was on the mind of men, and wailing went the weather,\n",
      "Yea, a sick cloud upon the soul when we were boys together.\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(r\"p[aeiou]{,2}t\",sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb927228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['poet', 'poet', 'poet', 'poet']\n"
     ]
    }
   ],
   "source": [
    "#find any p followed by at most 2 voewels and then a t\n",
    "for s in sents:\n",
    "    k=re.findall(\"p[aeiou]{,2}t\",s)\n",
    "    if len(k)>3:\n",
    "        print(k)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c12cffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.1200']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '10.1200'\n",
    "re.findall(\"\\d+(\\.\\d+)?\",s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d926b83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', 'Man', '', '', 'Was', '', '', 'hur', '', 'day', '', '', '', '', '', '', '', '', '', '', '', 'ton', '', '', '', '', '', '', '', '', 'To ', '', '', 'mun', '', '', '', 'ler', '', 'hew', '', 'Ben', '', 'ley', '', '', '', '', '', '', '', '', '', '', ' on', '', '', 'min', '', ' of', '', 'men', '', ' an', '', '', '', '', '', 'lin', '', '', 'wen', '', '', '', 'he ', '', '', '', '', 'her', '', '', '', '', '', '', 'sic', '', '', '', '', '', '', '', ' up', '', '', '', '', 'he ', '', '', '', '', '', '', 'hen', '', 'wer', '', '', 'boy', '', '', 'tog', '', '', 'her', '', '']\n"
     ]
    }
   ],
   "source": [
    "#match some vowel at the begging, match one vowel, \n",
    "#match some vowel at the beginning, find zero or more instances of the previous pattern\n",
    "for s in sents:\n",
    "    k=re.findall(\"([^aeiou][aeiou][^aeiou])*\",s)\n",
    "    if len(k)>3:\n",
    "        print(k)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda059e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'The', 'Man', 'Who', 'Was', 'Thursday', 'by', 'G', '.', 'K', '.', 'Chesterton', '1908', ']', 'To', 'Edmund', 'Clerihew', 'Bentley', 'A', 'cloud', 'was', 'on', 'the', 'mind', 'of', 'men', ',', 'and', 'wailing', 'went', 'the', 'weather', ',', 'Yea', ',', 'a', 'sick', 'cloud', 'upon', 'the', 'soul', 'when', 'we', 'were', 'boys', 'together', '.']\n"
     ]
    }
   ],
   "source": [
    "#at least one alpha numeric character or at the beginning match any alpha numeric character and any white space character atleast once\n",
    "for s in sents:\n",
    "    k=re.findall(\"\\w+|[^\\w\\s]+\",s)\n",
    "    if len(k)>3:\n",
    "        print(k)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf911c",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa52238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', 'a', '', '', '', '', '', '', '', 'a', '', '', '', '', '', '', '', '', 'a', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a', '', '', '', '', '', 'the', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'a', '', '', '', '', 'a', '', '', '', '', '', '', '', '', '', '', '', 'the', '', '', '', 'the', '', '', '', '', '', 'a', '', '', 'a', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'the', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'the', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "for s in sents:\n",
    "    k=re.findall(\"(a|an|the)*\",s)\n",
    "    if len(k)>3:\n",
    "        print(k)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a5e6b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in sents:\n",
    "    k=re.findall(\"\\d+(\\*|\\+)*\\d*\",s)\n",
    "    if len(k)>3:\n",
    "        print(k)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "655f94aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+', '*', '+', '']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"\\d*(\\*|\\+)*\\d*\",\"3+4*5+6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a0b586b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2.05', '.05', '+', '3', ''), ('', '', '*', '4', ''), ('', '', '+', '5', '')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "expression = \"2.05+3*4+5\"\n",
    "match_an_integer_or_decimal = '(\\d+(\\.\\d+)?)'\n",
    "match_zero_or_more_whitespace = '\\s*'\n",
    "matches_one_the_arithmetic_operators = '([+\\-*/])'\n",
    "pattern = match_an_integer_or_decimal+'*'+match_zero_or_more_whitespace+matches_one_the_arithmetic_operators+match_an_integer_or_decimal\n",
    "re.findall(pattern,expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bb0479",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99335ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK is a leading platform for building Python programs to work with human language data.\r\n",
      "It provides easy-to-use interfaces to over 50 corpora and lexical\r\n",
      "resources such as WordNet,\r\n",
      "along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\r\n",
      "wrappers for industrial-strength NLP libraries,\r\n",
      "and an active discussion forum.Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\r\n",
      "NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\r\n",
      "NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,”\r\n",
      "and “an amazing library to play with natural language.”Natural Language Processing with Python provides a practical\r\n",
      "introduction to programming for language processing.\r\n",
      "Written by the creators of NLTK, it guides the reader through the fundamentals\r\n",
      "of writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\r\n",
      "and more.\r\n",
      "The online version of the book has been been updated for Python 3 and NLTK 3.\r\n",
      "(The original Python 2 version is still available at https://www.nltk.org/book_1ed.)Tokenize and tag some text:Identify named entities:Display a parse tree:NB. If you publish work that uses NLTK, please cite the NLTK book as\r\n",
      "follows:Bird, Steven, Edward Loper and Ewan Klein (2009), Natural Language Processing with Python.  O’Reilly Media Inc.Sign up for release announcementsJoin in the discussion\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "url = \"https://www.nltk.org/\"\n",
    "raw = urlopen(url).read()\n",
    "soup = str(BeautifulSoup(raw))\n",
    "\n",
    "pattern = r\"<p>(.*?)</p>\"\n",
    "matches = ''.join(re.findall(pattern,soup,re.DOTALL))\n",
    "l = re.sub(r\"<.*?>\",\"\",matches)\n",
    "with open('corpus.txt','w+') as f:\n",
    "    f.write(l)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c4172",
   "metadata": {},
   "source": [
    "# Problem 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ea52f",
   "metadata": {},
   "source": [
    "* `\\s*`: Matches any whitespace characters (including spaces, tabs, and line breaks), if any, before the opening parenthesis.\n",
    "* `\\(`: Matches the opening parenthesis.\n",
    "* `[^)]*`: Matches any characters except closing parenthesis ), zero or more times, effectively matching the content inside the parentheses.\n",
    "* `\\)`: Matches the closing parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8166278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLTK is a leading platform for building Python programs to work with human language data.\\r\\nIt provides easy-to-use interfaces to over 50 corpora and lexical\\r\\nresources such as WordNet,\\r\\nalong with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning,\\r\\nwrappers for industrial-strength NLP libraries,\\r\\nand an active discussion forum.Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation,\\r\\nNLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.\\r\\nNLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,”\\r\\nand “an amazing library to play with natural language.”Natural Language Processing with Python provides a practical\\r\\nintroduction to programming for language processing.\\r\\nWritten by the creators of NLTK, it guides the reader through the fundamentals\\r\\nof writing Python programs, working with corpora, categorizing text, analyzing linguistic structure,\\r\\nand more.\\r\\nThe online version of the book has been been updated for Python 3 and NLTK 3.Tokenize and tag some text:Identify named entities:Display a parse tree:NB. If you publish work that uses NLTK, please cite the NLTK book as\\r\\nfollows:Bird, Steven, Edward Loper and Ewan Klein, Natural Language Processing with Python.  O’Reilly Media Inc.Sign up for release announcementsJoin in the discussion'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pattern = r\"\\((.*?)\\)</p>\"\n",
    "#pattern = r'(?<=\\(\\s*).*?\\.\\s*(?=\\))'\n",
    "pattern = r'\\s*\\([^)]*\\)'\n",
    "\n",
    "result = re.sub(pattern, '', l)\n",
    "#import nltk\n",
    "#re.findall(pattern,l)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fdae0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def load(f):\n",
    "    with open(f,'r') as f:\n",
    "        text = f.readlines()\n",
    "    exp1 = r'\\w+'\n",
    "    exp2 = r'\\r'\n",
    "    return nltk.regexp_tokenize(str(text),exp2)\n",
    "load('corpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b12ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
