{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1121a1ad",
   "metadata": {},
   "source": [
    "# Advanced Programming for AI\n",
    "\n",
    "# HW8 Classification1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20377ef3",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee33247",
   "metadata": {},
   "source": [
    "### Use the following data set for the problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a120bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X,y = make_classification(n_samples=1000, n_features=20, n_informative=18, n_redundant=2,\n",
    "                          n_repeated=0, n_classes=3)\n",
    "                          \n",
    "import pandas as pd\n",
    "data = pd.concat([pd.DataFrame(X),pd.DataFrame(y,columns=['class'])],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373bfd2c",
   "metadata": {},
   "source": [
    "# Problem 1: Make a python class that returns a train test validation split, call it `splitter`.\n",
    "\n",
    "* Let the arguments be `splitter(data,target)`\n",
    "    * `data` is the data set (without the target)\n",
    "    * `target` is the target class of interest; i.e. `data['target']`\n",
    "* Let there be *optional* arguments of `train_split`, `test_split`, `val_split` to describe the fractional distributions of the whole dataset\n",
    "    * If those arguments *arent* specified, then let the train split be 70%, test_split be 15% and val split be 15%\n",
    "        * *optional* means their initialized value is `None`\n",
    "    * Raise a `ValueError('splits must add to 1')` **if** the splits dont add to 1\n",
    "* Create a method called `split()` that returns `X_train,y_train,X_test,y_test,X_val,y_val` in that order\n",
    "    * Instantiating it would look like `X_train,y_train,X_test,y_test,X_val,y_val = splitter(data,'class').split()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d55a2",
   "metadata": {},
   "source": [
    "### Hint: The beginning of the class should look like;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a537bf",
   "metadata": {},
   "source": [
    "`from sklearn.model_selection import train_test_split\n",
    "class splitter:\n",
    "    def __init__(self,data,target,train_split=None,test_split=None,val_split=None):\n",
    "        self.y = data[target]\n",
    "        self.X = data.drop(target,axis=1)\n",
    "        if train_split is None:\n",
    "            self.train_split=0.7\n",
    "        else:\n",
    "            self.train_split=train_split\n",
    "            ....`\n",
    "            \n",
    "            finish the rest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d91f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "class splitter:\n",
    "    def __init__(self,data,target,train_split=None,test_split=None,val_split=None):\n",
    "        self.y = data[target]\n",
    "        self.X = data.drop(target,axis=1)\n",
    "        if train_split is None:\n",
    "            self.train_split=0.7\n",
    "        else:\n",
    "            self.train_split=train_split\n",
    "        if test_split is None:\n",
    "            self.test_split=0.15\n",
    "        else:\n",
    "            self.test_split=test_split\n",
    "        if val_split is None:\n",
    "            self.val_split=0.15\n",
    "        else:\n",
    "            self.val_split=val_split\n",
    "\n",
    "        if not self.train_split+self.test_split+self.val_split==1:\n",
    "            raise ValueError('splits must add to 1')\n",
    "    \n",
    "    def split(self):\n",
    "        test_size = self.test_split+self.val_split\n",
    "        val_size = self.val_split/test_size\n",
    "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_size)\n",
    "        X_test,X_val,y_test,y_val = train_test_split(X_test,y_test,test_size=val_size)\n",
    "        return X_train,y_train,X_test,y_test,X_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb9e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test,X_val,y_val = splitter(data,'class').split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d9beb",
   "metadata": {},
   "source": [
    "# Problem 2: Make a class that fits the model just like example 8 in the lecture 8 notebook. That class should inherit the `splitter` class and return a fitted model\n",
    "\n",
    "\n",
    "* The class should be instantiated using\n",
    "    * `model(LogisticRegression,[0.0001,0.001,0.01,0.1,1,10],data,'class')`\n",
    "* Include a `fit()` method that runs through all the possible hyper parameters, finding the best one\n",
    "* Include a `best_model()` method that find the best model just like example 6\n",
    "* Include a `report(y_pred,y_obs)` method that returns an `accuracy_score`\n",
    "\n",
    "\n",
    "\n",
    "### Hint: The beginning of the class should look like this (with a few more things to add to it in the constructor)\n",
    "\n",
    "`from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np`\n",
    "\n",
    "`class model(splitter):\n",
    "    def __init__(self,model,parameters,data,target):\n",
    "        self.model = model\n",
    "        self.model_best = model\n",
    "        self.parameters = parameters\n",
    "        self.score_reports = {}\n",
    "        self.scores = {}\n",
    "        self.max_score = 0\n",
    "        self.min_diff = np.inf\n",
    "        super().__init__(data,target)\n",
    "        self.X_train,self.y_train,self.X_test,self.y_test,self.X_val,self.y_val = super().split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6fabf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "class model(splitter):\n",
    "    def __init__(self,model,parameters,data,target):\n",
    "        self.model = model\n",
    "        self.model_best = model\n",
    "        self.parameters = parameters\n",
    "        self.score_reports = {}\n",
    "        self.scores = {}\n",
    "        self.max_score = 0\n",
    "        self.min_diff = np.inf\n",
    "        super().__init__(data,target)\n",
    "        self.X_train,self.y_train,self.X_test,self.y_test,self.X_val,self.y_val = super().split()\n",
    "        \n",
    "    def fit(self):\n",
    "        for c in self.parameters:\n",
    "            model = self.model(multi_class=\"multinomial\",solver=\"lbfgs\",C=c)\n",
    "            model.fit(self.X_train,self.y_train)\n",
    "            y_pred_val = model.predict(self.X_val)\n",
    "            y_pred_train = model.predict(self.X_train)\n",
    "            train_score = accuracy_score(y_pred_train,self.y_train)\n",
    "            val_score = accuracy_score(y_pred_val,self.y_val)\n",
    "            diff = np.abs(val_score-train_score)\n",
    "            self.score_reports[c] = classification_report(y_pred_val,y_val)\n",
    "            self.scores[c] = (val_score,train_score,diff)\n",
    "            if val_score>self.max_score:\n",
    "                self.max_score = val_score\n",
    "            if diff<self.min_diff:\n",
    "                self.min_diff = diff\n",
    "        return\n",
    "    \n",
    "    def report(self,y_pred,y_obs):\n",
    "        print('accuracy score: ',accuracy_score(y_pred,y_obs))\n",
    "    \n",
    "    def best_model(self):\n",
    "        self.fit()\n",
    "        self.c_best = [j for j in self.scores.keys() if self.scores[j][0]==self.max_score][0]\n",
    "        print(\"Best C value: \",self.c_best)\n",
    "        model_best = self.model_best(multi_class=\"multinomial\",solver=\"lbfgs\",C=self.c_best)\n",
    "        model_best.fit(self.X_train,self.y_train)\n",
    "        y_pred = model_best.predict(self.X_test)\n",
    "        self.report(y_pred,self.y_test)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ce5dba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C value:  1\n",
      "accuracy score:  0.66\n"
     ]
    }
   ],
   "source": [
    "m = model(LogisticRegression,[0.0001,0.001,0.01,0.1,1,10],data,'class')\n",
    "m.best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c1b45a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
